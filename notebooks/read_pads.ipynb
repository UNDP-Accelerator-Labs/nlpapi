{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29703eac-3eb5-4c54-b1ea-97a0af3a3996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import contextlib\n",
    "import collections\n",
    "\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import urllib.parse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70015141-a072-4c8e-b319-8cfdb8153284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from html import unescape\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1926be27-7c3c-4c1e-a66b-da10ca26e39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    while True:\n",
    "        prev_text = text\n",
    "        text = unescape(text)\n",
    "        if prev_text == text:\n",
    "            break\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    return re.sub(\"\\n\\n\\n+\", \"\\n\\n\", re.sub(\"[ \\t]+\", \" \", re.sub(\"\\n[ \\t]+\", \"\\n\", re.sub(\"\\n\\n+\", \"\\n\", re.sub(\"\\r\", \"\\n\", text)))))\n",
    "\n",
    "def strip_html(text: str) -> str:\n",
    "    return re.sub(r\"<(?:\\\"[^\\\"]*\\\"['\\\"]*|'[^']*'['\\\"]*|[^'\\\">])+>\", \"\", re.sub(r\"<br\\s*/?\\s*>\", \"\\n\", text.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "118df9c1-ec72-47de-8855-e56770751a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG_PATH = \"config.json\"\n",
    "CONFIG_PATH = \"config_local.json\"\n",
    "# LIMIT = None\n",
    "LIMIT = 10\n",
    "VERBOSE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58365e68-94f9-4bdf-b776-b8c50d55c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = None\n",
    "ENGINES = {}\n",
    "TABLES = {}\n",
    "BINDS = {}\n",
    "SESSION = None\n",
    "\n",
    "\n",
    "def config_template():\n",
    "    default_conn = {\n",
    "        \"dialect\": \"postgresql\",\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": 5432,\n",
    "        \"dbname\": \"INVALID\",\n",
    "        \"schema\": \"public\",\n",
    "        \"user\": \"INVALID\",\n",
    "        \"passwd\": \"INVALID\",\n",
    "    }\n",
    "    return {\n",
    "        \"dbs\": {\n",
    "            \"login\": default_conn.copy(),\n",
    "            \"sm\": default_conn.copy(),\n",
    "            \"exp\": default_conn.copy(),\n",
    "            \"ap\": default_conn.copy(),\n",
    "            \"blogs\": default_conn.copy(),\n",
    "        },\n",
    "        \"nlpapi\": {\n",
    "            \"host\": \"localhost\",\n",
    "            \"token\": \"INVALID\",\n",
    "            \"write_access\": \"INVALID\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def get_config():\n",
    "    global CONFIG\n",
    "    \n",
    "    if CONFIG is not None:\n",
    "        return CONFIG\n",
    "    if not os.path.exists(CONFIG_PATH):\n",
    "        with open(CONFIG_PATH, \"w\") as fout:\n",
    "            print(json.dumps(config_template(), indent=4, sort_keys=True), file=fout)\n",
    "        raise ValueError(\n",
    "            f\"config file missing. new file was created at '{CONFIG_PATH}'. \"\n",
    "            \"please correct values in file and run again\")\n",
    "    with open(CONFIG_PATH, \"r\") as fin:\n",
    "        CONFIG = json.load(fin)\n",
    "    config_out = {\n",
    "        \"dbs\": {\n",
    "            \"login\": CONFIG[\"dbs\"][\"login\"].copy(),\n",
    "            \"sm\": CONFIG[\"dbs\"][\"sm\"].copy(),\n",
    "            \"exp\": CONFIG[\"dbs\"][\"exp\"].copy(),\n",
    "            \"ap\": CONFIG[\"dbs\"][\"ap\"].copy(),\n",
    "            \"blogs\": CONFIG[\"dbs\"][\"blogs\"].copy(),\n",
    "        },\n",
    "         \"nlpapi\": CONFIG[\"nlpapi\"].copy(),\n",
    "    }\n",
    "    config_out[\"dbs\"][\"login\"][\"passwd\"] = \"*****\"\n",
    "    config_out[\"dbs\"][\"sm\"][\"passwd\"] = \"*****\"\n",
    "    config_out[\"dbs\"][\"exp\"][\"passwd\"] = \"*****\"\n",
    "    config_out[\"dbs\"][\"ap\"][\"passwd\"] = \"*****\"\n",
    "    config_out[\"dbs\"][\"blogs\"][\"passwd\"] = \"*****\"\n",
    "    config_out[\"nlpapi\"][\"token\"] = \"*****\"\n",
    "    config_out[\"nlpapi\"][\"write_access\"] = \"*****\"\n",
    "    print(f\"loaded config\\n{json.dumps(config_out, indent=2, sort_keys=True)}\")\n",
    "    return CONFIG\n",
    "\n",
    "\n",
    "def get_engine(dbname):\n",
    "    res = ENGINES.get(dbname)\n",
    "    if res is not None:\n",
    "        return res\n",
    "    db = get_config()[\"dbs\"][dbname]\n",
    "    user = urllib.parse.quote(db[\"user\"])\n",
    "    passwd = urllib.parse.quote(db[\"passwd\"])\n",
    "    engine = sa.create_engine(\n",
    "        f\"{db['dialect']}://{user}:{passwd}@{db['host']}:{db['port']}/{db['dbname']}\",\n",
    "        echo=VERBOSE)\n",
    "    engine = engine.execution_options(\n",
    "        schema_translate_map={None: db['schema']})\n",
    "    res = engine, sa.MetaData()\n",
    "    ENGINES[dbname] = res\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_table(dbname, tablename):\n",
    "    global SESSION\n",
    "    \n",
    "    key = (dbname, tablename)\n",
    "    res = TABLES.get(key)\n",
    "    if res is not None:\n",
    "        return res\n",
    "    SESSION = None\n",
    "    engine, metadata = get_engine(dbname)\n",
    "    res = sa.Table(\n",
    "        tablename,\n",
    "        metadata,\n",
    "        autoload_with=engine)\n",
    "    TABLES[key] = res\n",
    "    BINDS[res] = engine\n",
    "    return res\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def get_session():\n",
    "    global SESSION\n",
    "    \n",
    "    session = SESSION\n",
    "    if session is None:\n",
    "        session = sessionmaker()\n",
    "        session.configure(binds=BINDS)\n",
    "        SESSION = session\n",
    "    with session() as res:\n",
    "        yield res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9da52d2c-bd3b-46f0-b087-38ed258acc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_nlpapi(path: str, payload: dict, *, is_write: bool, is_print: bool) -> dict:\n",
    "    config = get_config()[\"nlpapi\"]\n",
    "    protocol = \"https://\"\n",
    "    if \"localhost\" in config['host']:\n",
    "        protocol = \"http://\"\n",
    "    url = f\"{protocol}{config['host']}{path}\"\n",
    "    if is_print:\n",
    "        print(url)\n",
    "    retry = 0\n",
    "    while True:\n",
    "        try:\n",
    "            res = requests.post(url, json={\n",
    "                **payload,\n",
    "                \"token\": config[\"token\"],\n",
    "                **({\"write_access\": config[\"write_access\"]} if is_write else {}),\n",
    "            }, timeout=900)\n",
    "            res.raise_for_status()\n",
    "            return res.json()\n",
    "        except (requests.exceptions.Timeout, requests.exceptions.HTTPError):\n",
    "            retry += 1\n",
    "            if retry > 6:\n",
    "                raise\n",
    "            time.sleep(retry * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71532661-7c09-411d-a73f-41be0d1a89f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded config\n",
      "{\n",
      "  \"dbs\": {\n",
      "    \"ap\": {\n",
      "      \"dbname\": \"undp_ap\",\n",
      "      \"dialect\": \"postgresql\",\n",
      "      \"host\": \"localhost\",\n",
      "      \"passwd\": \"*****\",\n",
      "      \"port\": 5432,\n",
      "      \"schema\": \"public\",\n",
      "      \"user\": \"krause\"\n",
      "    },\n",
      "    \"blogs\": {\n",
      "      \"dbname\": \"blogs\",\n",
      "      \"dialect\": \"postgresql\",\n",
      "      \"host\": \"acclabs.postgres.database.azure.com\",\n",
      "      \"passwd\": \"*****\",\n",
      "      \"port\": 5432,\n",
      "      \"schema\": \"public\",\n",
      "      \"user\": \"undpacclab@acclabs\"\n",
      "    },\n",
      "    \"exp\": {\n",
      "      \"dbname\": \"undp_exp\",\n",
      "      \"dialect\": \"postgresql\",\n",
      "      \"host\": \"localhost\",\n",
      "      \"passwd\": \"*****\",\n",
      "      \"port\": 5432,\n",
      "      \"schema\": \"public\",\n",
      "      \"user\": \"krause\"\n",
      "    },\n",
      "    \"login\": {\n",
      "      \"dbname\": \"undp_login\",\n",
      "      \"dialect\": \"postgresql\",\n",
      "      \"host\": \"localhost\",\n",
      "      \"passwd\": \"*****\",\n",
      "      \"port\": 5432,\n",
      "      \"schema\": \"public\",\n",
      "      \"user\": \"krause\"\n",
      "    },\n",
      "    \"sm\": {\n",
      "      \"dbname\": \"undp_sm\",\n",
      "      \"dialect\": \"postgresql\",\n",
      "      \"host\": \"localhost\",\n",
      "      \"passwd\": \"*****\",\n",
      "      \"port\": 5432,\n",
      "      \"schema\": \"public\",\n",
      "      \"user\": \"krause\"\n",
      "    }\n",
      "  },\n",
      "  \"nlpapi\": {\n",
      "    \"host\": \"localhost:8080\",\n",
      "    \"token\": \"*****\",\n",
      "    \"write_access\": \"*****\"\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/zrdw3xx56dd1w9xbl6x_yl0c0000gn/T/ipykernel_39942/98962730.py:94: SAWarning: Did not recognize type 'ltree' of column 'version'\n",
      "  res = sa.Table(\n",
      "/var/folders/ff/zrdw3xx56dd1w9xbl6x_yl0c0000gn/T/ipykernel_39942/98962730.py:94: SAWarning: Did not recognize type 'public_old.ltree' of column 'version'\n",
      "  res = sa.Table(\n"
     ]
    }
   ],
   "source": [
    "# global tables\n",
    "t_tags = get_table(\"login\", \"tags\")\n",
    "t_users = get_table(\"login\", \"users\")\n",
    "\n",
    "# solution mapping tables\n",
    "t_sm_pads = get_table(\"sm\", \"pads\")\n",
    "t_sm_tagging = get_table(\"sm\", \"tagging\")\n",
    "\n",
    "# action plan tables\n",
    "t_ap_pads = get_table(\"ap\", \"pads\")\n",
    "t_ap_tagging = get_table(\"ap\", \"tagging\")\n",
    "\n",
    "# experiments tables\n",
    "t_exp_pads = get_table(\"exp\", \"pads\")\n",
    "t_exp_tagging = get_table(\"exp\", \"tagging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "410e8a00-4b23-4b40-913c-3a44217ea307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/api/query_embed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hits': [], 'status': 'ok'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_nlpapi(\"/api/query_embed\", {\n",
    "    \"input\": \"africa\",\n",
    "    \"offset\": 0,\n",
    "    \"limit\": 10,\n",
    "    \"db\": \"main\",\n",
    "    \"score_threshold\": 0.2,\n",
    "    \"filters\": {\"iso3\": [\"EGY\"]},\n",
    "}, is_write=False, is_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a42bd50b-bb04-4d8a-b2b1-30ce11eb782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {}\n",
    "with get_session() as session:\n",
    "    stmt = sa.select(t_tags.c.id, t_tags.c.name, t_tags.c.type)\n",
    "    for row in session.execute(stmt):\n",
    "        tags[f\"{row[2]}-{row[0]}\"] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad166308-eaa1-4094-8e30-d25f07485c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_map = {\n",
    "    2: \"preview\",\n",
    "    3: \"public\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "770d8241-6f5b-497c-92e8-5e7ba0d45784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip_ahead = 5250\n",
    "skip_ahead = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5799605-80d0-4ed5-a074-379f172d1775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing solution\n",
      "adding #0 solution 2 preview 2023-01-16 03:33:43.843095-05:00\n",
      "http://localhost:8080/api/add_embed\n",
      "took avg 3.489445916027762s for 1\n",
      "processing actionplan\n",
      "processing experiment\n"
     ]
    }
   ],
   "source": [
    "with get_session() as session:\n",
    "    destination = \"main\"  # \"test\"\n",
    "    names = [\"solution\", \"actionplan\", \"experiment\"]\n",
    "    urls = [\n",
    "        \"https://solutions.sdg-innovation-commons.org/en/view/pad?id=\",\n",
    "        \"https://learningplans.sdg-innovation-commons.org/en/view/pad?id=\",\n",
    "        \"https://experiments.sdg-innovation-commons.org/en/view/pad?id=\",\n",
    "    ]\n",
    "    dbs = [\n",
    "        t_sm_pads,\n",
    "        t_ap_pads,\n",
    "        t_exp_pads,\n",
    "    ]\n",
    "    doc_types = [\n",
    "        \"solution\",\n",
    "        \"action plan\",\n",
    "        \"experiment\",\n",
    "    ]    \n",
    "    count = 0\n",
    "    start_total_time = time.monotonic()\n",
    "    try:\n",
    "        for (name, url_prefix, pad_db, doc_type) in zip(names, urls, dbs, doc_types):\n",
    "            stmt = sa.select(pad_db.c.status, pad_db.c.full_text, pad_db.c.id, pad_db.c.update_at, pad_db.c.title)\n",
    "            stmt = stmt.where(pad_db.c.status > 1)\n",
    "            stmt = stmt.order_by(pad_db.c.id)\n",
    "            if LIMIT is not None:\n",
    "                stmt = stmt.limit(LIMIT)\n",
    "            start_time = time.monotonic()\n",
    "            time_count = 0\n",
    "            print(f\"processing {name}\")\n",
    "            for row in session.execute(stmt):\n",
    "                if count < skip_ahead:\n",
    "                    count += 1\n",
    "                    continue\n",
    "                status = status_map[int(row[0])]\n",
    "                if count % 100 == 0:\n",
    "                    print(f\"adding #{count} {name} {row[2]} {status} {row[3]}\")\n",
    "                url = f\"{url_prefix}{int(row[2])}\"\n",
    "                title = row[4]\n",
    "                if row[3]:\n",
    "                    date = datetime.fromisoformat(f\"{row[3]}\").isoformat()\n",
    "                else:\n",
    "                    date = None\n",
    "                call_nlpapi(\"/api/add_embed\", {\n",
    "                    \"input\": f\"{row[1]}\",\n",
    "                    \"base\": f\"{name}\",\n",
    "                    \"doc_id\": int(row[2]),\n",
    "                    \"url\": url,\n",
    "                    \"title\": title,\n",
    "                    \"meta\": {\n",
    "                        \"status\": status,\n",
    "                        \"date\": date,\n",
    "                        \"doc_type\": doc_type,\n",
    "                    },\n",
    "                    \"db\": destination,\n",
    "                }, is_write=True, is_print=count % 100 == 0)\n",
    "                time_count += 1\n",
    "                if count % 100 == 0:\n",
    "                    print(\n",
    "                        f\"took avg {(time.monotonic() - start_time) / time_count if time_count > 0 else '?'}s for {time_count}\")\n",
    "                    first = False\n",
    "                    start_time = time.monotonic()\n",
    "                    time_count = 0\n",
    "                count += 1\n",
    "    finally:\n",
    "        duration = time.monotonic() - start_total_time\n",
    "        print(f\"processed: {count} in {duration}s avg time {duration / (count - skip_ahead) if (count - skip_ahead) > 0 else '?'}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c268d-ff17-4a6d-8a63-b4ae76b98ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_nlpapi(\n",
    "    \"/api/build_index\", \n",
    "    {\n",
    "        \"db\": destination,\n",
    "    },\n",
    "    is_write=True,\n",
    "    is_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1e6e9a-d1a8-427a-bf1b-7f92593ee8e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with get_session() as session:\n",
    "    for name, pad_db in zip(names, dbs):\n",
    "        if name not in {\"actionplan\"}:\n",
    "            continue\n",
    "        stmt = sa.select(pad_db.c.status, pad_db.c.full_text, pad_db.c.id, pad_db.c.update_at, pad_db.c.title)\n",
    "        stmt = stmt.where(pad_db.c.id == 1883)\n",
    "        for row in session.execute(stmt):\n",
    "            print(f\"name: {name}\")\n",
    "            print(f\"id: {row[2]}\")\n",
    "            print(f\"title: {row[4]}\")\n",
    "            print(f\"status: {row[0]}\")\n",
    "            print(f\"update_at: {row[3]}\")\n",
    "            print(f\"full_text: {row[1]}\")\n",
    "            full_text = f\"{row[1]}\"\n",
    "            display(\n",
    "                call_nlpapi(\"/api/extract\", {\"modules\": [{\"name\": \"location\"}, {\"name\": \"language\"}], \"input\": full_text}, is_write=False, is_print=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d4dd7e-3f59-404d-84d4-0e855ab31fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_articles = get_table(\"blogs\", \"articles\")\n",
    "t_article_content = get_table(\"blogs\", \"article_content\")\n",
    "t_raw_html = get_table(\"blogs\", \"raw_html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a52e28e-3650-43ce-afb4-9267e62e590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip_ahead = 3699\n",
    "skip_ahead = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18106c-a57c-4751-9cc8-86d5e77feb8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# destination = \"main\"  # \"test\"\n",
    "count = 0\n",
    "start_total_time = time.monotonic()\n",
    "try:\n",
    "    with get_session() as session:\n",
    "        start_time = time.monotonic()\n",
    "        time_count = 0\n",
    "        stmt = sa.select(\n",
    "            t_articles.c.id,  # 0\n",
    "            t_articles.c.url,  # 1\n",
    "            t_articles.c.title,  # 2\n",
    "            t_articles.c.posted_date,  # 3\n",
    "            t_articles.c.article_type,  # 4\n",
    "            t_articles.c.relevance,  # 5\n",
    "            t_article_content.c.article_id,  # 6\n",
    "            t_article_content.c.content,  # 7\n",
    "            t_articles.c.posted_date_str,  # 8\n",
    "            t_raw_html.c.article_id,  # 9\n",
    "            t_raw_html.c.raw_html)  # 10\n",
    "        stmt = stmt.where(sa.and_(t_article_content.c.article_id == t_articles.c.id, t_raw_html.c.article_id == t_articles.c.id))\n",
    "        stmt = stmt.order_by(t_articles.c.id)\n",
    "        for row in session.execute(stmt):\n",
    "            if row[5] <= 1:\n",
    "                # print(f\"skip {row[0]} -- relevance <= 1 {row[5]}\")\n",
    "                continue\n",
    "            if not row[7]:\n",
    "                continue\n",
    "            content = f\"{row[7]}\".strip()\n",
    "            if not content:\n",
    "                continue\n",
    "            if count < skip_ahead:\n",
    "                count += 1\n",
    "                continue\n",
    "            if LIMIT is not None and count >= LIMIT:\n",
    "                break\n",
    "            status = \"public\"\n",
    "            if count % 100 == 0:\n",
    "                print(f\"adding #{count} blog {row[2]} {status} {row[3]}\")\n",
    "            url = f\"{row[1]}\".strip()\n",
    "            if row[3]:\n",
    "                date = datetime.fromisoformat(f\"{row[3]}\").isoformat()\n",
    "            else:\n",
    "                dates = call_nlpapi(\n",
    "                    \"/api/date\", \n",
    "                    {\n",
    "                        \"raw_html\": row[10],\n",
    "                        \"posted_date_str\": row[8],\n",
    "                        \"language\": None,\n",
    "                        \"use_date_str\": True,\n",
    "                    },\n",
    "                    is_write=False,\n",
    "                    is_print=False)\n",
    "                date = dates[\"date\"]\n",
    "            title = row[2]\n",
    "            if title:\n",
    "                content = f\"{title}\\n\\n{content}\"\n",
    "            call_nlpapi(\"/api/add_embed\", {\n",
    "                \"input\": content,\n",
    "                \"base\": \"blog\",\n",
    "                \"doc_id\": int(row[0]),\n",
    "                \"url\": url,\n",
    "                \"title\": title,\n",
    "                \"meta\": {\n",
    "                    \"status\": status,\n",
    "                    \"date\": date,\n",
    "                    \"doc_type\": f\"{row[4]}\",\n",
    "                },\n",
    "                \"db\": destination,\n",
    "            }, is_write=True, is_print=count % 100 == 0)\n",
    "            time_count += 1\n",
    "            if count % 100 == 0:\n",
    "                print(\n",
    "                    f\"took avg {(time.monotonic() - start_time) / time_count if time_count > 0 else '?'}s for {time_count}\")\n",
    "                first = False\n",
    "                start_time = time.monotonic()\n",
    "                time_count = 0\n",
    "            count += 1\n",
    "finally:\n",
    "    duration = time.monotonic() - start_total_time\n",
    "    print(f\"processed: {count} in {duration}s avg time {duration / (count - skip_ahead) if (count - skip_ahead) > 0 else '?'}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab5480-c01e-4365-88c0-3b48eb50e09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_nlpapi(\n",
    "    \"/api/build_index\", \n",
    "    {\n",
    "        \"db\": destination,\n",
    "    },\n",
    "    is_write=True,\n",
    "    is_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e9333-60a0-429e-bd45-3d25f3b183d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_session() as session:\n",
    "    stmt = sa.select(\n",
    "        t_articles.c.id,  # 0\n",
    "        t_articles.c.url,  # 1\n",
    "        t_articles.c.title,  # 2\n",
    "        t_articles.c.posted_date,  # 3\n",
    "        t_articles.c.article_type,  # 4\n",
    "        t_articles.c.relevance,  # 5\n",
    "        t_article_content.c.article_id,  # 6\n",
    "        t_article_content.c.content)  # 7\n",
    "    stmt = stmt.where(sa.and_(t_article_content.c.article_id == t_articles.c.id, t_articles.c.id == 14091))\n",
    "    stmt = stmt.order_by(t_articles.c.id)\n",
    "    for row in session.execute(stmt):\n",
    "        content = f\"{row[7]}\".strip()\n",
    "        if not content or content.lower() == \"none\" or content.lower() == \"null\":\n",
    "            content = \"\"\n",
    "        url = f\"{row[1]}\".strip()\n",
    "        title = f\"{row[2]}\".strip()\n",
    "        if not title or title.lower() == \"none\" or title.lower() == \"null\":\n",
    "            title = url\n",
    "        content = f\"{title}\\n\\n{content}\"\n",
    "        print(f\"id: {row[0]}\")\n",
    "        print(f\"url: {url}\")\n",
    "        print(f\"title: {title}\")\n",
    "        print(f\"date: {row[3]}\")\n",
    "        print(f\"type: {row[4]}\")\n",
    "        print(f\"relevance: {row[5]}\")\n",
    "        print(f\"content: {content[:100]}\")\n",
    "        # print(\n",
    "        #     json.dumps(\n",
    "        #         call_nlpapi(\n",
    "        #             \"/api/extract\",\n",
    "        #             {\"modules\": [{\"name\": \"location\"}, {\"name\": \"language\"}], \"input\": content},\n",
    "        #             is_write=False,\n",
    "        #             is_print=True),\n",
    "        #         sort_keys=True,\n",
    "        #         indent=2))\n",
    "        snippets = call_nlpapi(\n",
    "            \"/api/snippify\",\n",
    "            {\"input\": content},\n",
    "            is_write=False,\n",
    "            is_print=True)\n",
    "        print(json.dumps(snippets, sort_keys=True, indent=2))\n",
    "        shorts = call_nlpapi(\n",
    "            \"/api/snippify\",\n",
    "            {\"input\": snippets[\"snippets\"][0], \"small_snippets\": True},\n",
    "            is_write=False,\n",
    "            is_print=True)\n",
    "        print(json.dumps(shorts, sort_keys=True, indent=2))\n",
    "        stest = call_nlpapi(\n",
    "            \"/api/snippify\",\n",
    "            {\"input\": snippets[\"snippets\"][0], \"chunk_size\": 60, \"chunk_padding\": 20},\n",
    "            is_write=False,\n",
    "            is_print=True)\n",
    "        print(json.dumps(stest, sort_keys=True, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea899d8-8618-4c2b-85f2-38da5315a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "with get_session() as session:\n",
    "    stmt = sa.select(t_articles.c.url)\n",
    "    for row in session.execute(stmt):\n",
    "        urls.append(f\"{row[0]}\".strip())\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344681f5-2c9a-4ba6-aa4b-689208092443",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv(\"countries.csv\")\n",
    "country_map = {}\n",
    "for _, row in countries.iterrows():\n",
    "    country_map[row[\"name\"].lower().replace(\" \", \"-\")] = row[\"iso3\"].strip()\n",
    "len(country_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9203f0-042d-451d-99e7-8a5d5d5970fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_url(country_set, found_countries, url):\n",
    "    purl = url.removeprefix(\"https://www.undp.org/\")\n",
    "    for lang in (\n",
    "            \"ar\", \"az\", \"bs\", \"cnr\", \"da\", \"de\", \"es\", \"fi\", \"fr\", \"id\", \"ja\", \"ka\", \"kk\", \"km\", \"ko\", \"ku\", \"ky\", \"no\",\n",
    "            \"pt\", \"ro\", \"ru\", \"sr\", \"sv\", \"tr\", \"uk\", \"uz\", \"vi\", \"zh\"):\n",
    "        turl = purl.removeprefix(f\"{lang}/\")\n",
    "        if turl != purl:\n",
    "            purl = turl\n",
    "            break\n",
    "    fix = purl.find(\"/\")\n",
    "    if fix < 0:\n",
    "        return\n",
    "    pres = purl[:fix]\n",
    "    if pres in (\n",
    "            \"https:\",\n",
    "            \"about-us\",\n",
    "            \"acceleratorlabs\",\n",
    "            \"accountability\",\n",
    "            \"careers\",\n",
    "            \"energy\",\n",
    "            \"publications\",\n",
    "            \"events\",\n",
    "            \"executive-board\",\n",
    "            \"approvisionnement\",\n",
    "            \"blog\",\n",
    "            \"press-releases\",\n",
    "            \"speeches\",\n",
    "            \"policy-centre\",\n",
    "            \"seoul-policy-centre\",\n",
    "            \"node\",\n",
    "            \"papp\",\n",
    "            \"procurement\",\n",
    "            \"rolhr\",\n",
    "            \"romecentre\",\n",
    "            \"sgtechcentre\",\n",
    "            \"sites\",\n",
    "            \"stories\"):\n",
    "        return\n",
    "    if pres in (\"africa\", \"arab-states\", \"asia-pacific\", \"latin-america\", \"eurasia\", \"european-union\", \"geneva\", \"pacific\"):\n",
    "        return\n",
    "    if pres in country_map:\n",
    "        found_countries.add(country_map[pres])\n",
    "        return\n",
    "    country_set[pres].append(url)\n",
    "\n",
    "country_set = collections.defaultdict(list)\n",
    "found_countries = set()\n",
    "for url in urls:\n",
    "    process_url(country_set, found_countries, url)\n",
    "country_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e288be-57ee-4d31-9fa2-f1b601e73dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(found_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664cee23-d344-4efc-839c-e5ecc4818fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_session() as session:\n",
    "    stmt = sa.select(\n",
    "        t_articles.c.id,  # 0\n",
    "        t_articles.c.url,  # 1\n",
    "        t_articles.c.title,  # 2\n",
    "        t_articles.c.posted_date_str,  # 3\n",
    "        t_articles.c.language,  # 4\n",
    "        t_articles.c.relevance,  # 5\n",
    "        t_raw_html.c.article_id,  # 6\n",
    "        t_raw_html.c.raw_html)  # 7\n",
    "    stmt = stmt.where(sa.and_(t_raw_html.c.article_id == t_articles.c.id, t_articles.c.id == 14091))\n",
    "    stmt = stmt.order_by(t_articles.c.id)\n",
    "    for row in session.execute(stmt):\n",
    "        print(f\"id: {row[0]}\")\n",
    "        print(f\"url: {row[1]}\")\n",
    "        print(f\"title: {row[2]}\")\n",
    "        print(f\"date: {row[3]}\")\n",
    "        print(f\"language: {row[4]}\")\n",
    "        print(f\"relevance: {row[5]}\")\n",
    "        print(f\"content length: {len(row[7])}\")\n",
    "        dates = call_nlpapi(\n",
    "            \"/api/date\",\n",
    "            {\n",
    "                \"raw_html\": row[7],\n",
    "                \"posted_date_str\": row[3],  # can be None\n",
    "                \"language\": row[4],  # can be None\n",
    "                \"use_date_str\": True,\n",
    "            },\n",
    "            is_write=False,\n",
    "            is_print=True)\n",
    "        print(json.dumps(dates, sort_keys=True, indent=2))\n",
    "        dates = call_nlpapi(\n",
    "            \"/api/date\",\n",
    "            {\n",
    "                \"raw_html\": row[7],\n",
    "                \"posted_date_str\": None,  # can be None\n",
    "                \"language\": None,  # can be None\n",
    "                \"use_date_str\": True,\n",
    "            },\n",
    "            is_write=False,\n",
    "            is_print=True)\n",
    "        print(json.dumps(dates, sort_keys=True, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40374bf4-21fd-4492-a5fa-f77cfe4ee902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
