{
  "graphs": [
    {
      "name": "llama",
      "description": "llama chat model",
      "input": "node_0",
      "input_format": {
        "prompt": "string",
        "main_prompt": "string",
        "post_prompt": "string"
      },
      "output_format": {
        "response": "string"
      },
      "nodes": [
        {
          "name": "node_0",
          "kind": "nlpapi.node_llama",
          "args": {
            "model_path": "models/Meta-Llama-3-8B-Instruct-IQ3_XS.gguf",
            "n_ctx": 30000,
            "n_gpu_layers": -1
          },
          "outs": {
            "out": null
          },
          "vmap": {
            "prompt": ":prompt",
            "main_prompt": ":main_prompt",
            "post_prompt": ":post_prompt"
          }
        }
      ],
      "vmap": {
        "response": "node_0:response"
      },
      "cache": false
    }
  ],
  "entry": "llama"
}
